{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33df9c78-4a56-4f92-894a-f2c13afc2b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pysr import PySRRegressor\n",
    "\n",
    "import importlib\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import functions_symbollic_regression as func_symb_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "797097cf-092c-41b9-9aeb-c9af738c7e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_galactic_properties(file_path, file_name):\n",
    "\n",
    "    print(\"I am in the read_galactic_properties function\")\n",
    "\n",
    "    # Read the DataFrame, skipping the header lines\n",
    "    galaxies = pd.read_csv(\n",
    "        f\"{file_path}/{file_name}\", \n",
    "        sep=',', \n",
    "    )\n",
    "\n",
    "\n",
    "    galaxies['alpha_co_cloudy'] = galaxies['h2_mass_cloudy'] / galaxies['L_co_10'] \n",
    "    galaxies['X_co_cloudy'] = galaxies['alpha_co_cloudy'] * 6.3e19 \n",
    "\n",
    "\n",
    "    galaxies['alpha_co_semi_analytical'] = galaxies['h2_mass_semi_analytical'] / galaxies['L_co_10']\n",
    "    galaxies['X_co_semi_analytical'] = galaxies['alpha_co_semi_analytical'] * 6.3e19 \n",
    "\n",
    "    return galaxies \n",
    "\n",
    "\n",
    "def take_log_of_the_data(data):\n",
    "\n",
    "    print(\"I am in the take_log_of_the_data function\")\n",
    "    \n",
    "    # Taking the logarithm of the data\n",
    "    log_data = pd.DataFrame()\n",
    "\n",
    "    not_log_taken_columns = [\n",
    "        'name', 'galaxy_type', 'redshift', 'number_of_NaN_indices', 'alpha_co_cloudy', 'X_co_cloudy', 'alpha_co_semi_analytical', 'X_co_semi_analytical'\n",
    "        ]\n",
    "    \n",
    "    columns = [col for col in data.columns if col not in not_log_taken_columns]\n",
    "    \n",
    "    for key in data.keys():\n",
    "        if key in columns:\n",
    "            log_data[f\"log_{key}\"] = np.log10(data[key])\n",
    "        else: \n",
    "            log_data[key] = data[key]\n",
    "\n",
    "\n",
    "    # Delete Nan and inf\n",
    "    log_data = log_data[~log_data.isin([np.inf, -np.inf, np.nan]).any(axis=1)] \n",
    "    \n",
    "    return log_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1d9d88-00e9-4120-9188-014268151c17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_dir = \"/scratch/m/murray/dtolgay/post_processing_fire_outputs/skirt/python_files\"\n",
    "\n",
    "# Define the file path\n",
    "file_path = f\"{base_dir}/analyze_hden_metallicity_turbulence_isrf_radius/data\"\n",
    "# file_name = \"galactic_properties_averageSobolevH_hybridInterpolator_z0_usingIvalues.csv\"\n",
    "\n",
    "file_name = \"galactic_properties_smoothingLength_RBFInterpolator_z0_usingFvalues_voronoi_1e5.csv\"\n",
    "z0 = read_galactic_properties(file_path=file_path, file_name=file_name)\n",
    "\n",
    "file_name = \"galactic_properties_smoothingLength_RBFInterpolator_z1_usingFvalues_voronoi_1e5.csv\"\n",
    "z1 = read_galactic_properties(file_path=file_path, file_name=file_name)\n",
    "\n",
    "file_name = \"galactic_properties_smoothingLength_RBFInterpolator_z2_usingFvalues_voronoi_1e5.csv\"\n",
    "z2 = read_galactic_properties(file_path=file_path, file_name=file_name)\n",
    "\n",
    "file_name = \"galactic_properties_smoothingLength_RBFInterpolator_z3_usingFvalues_voronoi_1e5.csv\"\n",
    "z3 = read_galactic_properties(file_path=file_path, file_name=file_name)\n",
    "\n",
    "# Merge the three redshifts \n",
    "merged_df = pd.concat([z0, z1, z2, z3], ignore_index=True)\n",
    "\n",
    "# # TODO: Use only z=3 \n",
    "# condition_z = merged_df['redshift'].astype(str) == \"3.0\"\n",
    "# merged_df = merged_df[condition_z].copy()\n",
    "\n",
    "# Take logarithm of the data \n",
    "data_df = take_log_of_the_data(data=merged_df)\n",
    "data_df_original = data_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb770a8-ce32-4d45-bae9-acc30e2f020a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Dictionary mapping feature column names to their LaTeX-formatted symbols\n",
    "# x_vars = {\n",
    "#     \"log_metallicity_gas_half_light_visible_z500pc\": {\n",
    "#         \"symbol\": r\"$\\log_{10}(Z_{\\mathrm{gas}}(R_{50}))$\"\n",
    "#     },\n",
    "#     \"log_metalicity_star_half_light_visible_z500pc\": {\n",
    "#         \"symbol\": r\"$\\log_{10}(Z_{\\star}(R_{50}))$\"\n",
    "#     },\n",
    "#     \"log_sfr_10Myr\": {\n",
    "#         \"symbol\": r\"$\\log_{10}(\\mathrm{SFR}_{10\\,\\mathrm{Myr}})$\"\n",
    "#     },\n",
    "#     \"log_star_mass\": {\n",
    "#         \"symbol\": r\"$\\log_{10}(M_\\star)$\"\n",
    "#     },\n",
    "#     \"log_gas_mass\": {\n",
    "#         \"symbol\": r\"$\\log_{10}(M_{\\mathrm{gas}})$\"\n",
    "#     }, \n",
    "#     \"log_Pgas_half_light_visible_z500pc\": {\n",
    "#         \"symbol\": r\"$\\log_{10}(P_{\\mathrm{gas}}(R_{50}))$\"\n",
    "#     },\n",
    "#     \"log_Pstar_half_light_visible_z500pc\": {\n",
    "#         \"symbol\": r\"$\\log_{10}(P_{\\mathrm{star}}(R_{50}))$\"\n",
    "#     },\n",
    "#     \"log_Ptotal_half_light_visible_z500pc\": {\n",
    "#         \"symbol\": r\"$\\log_{10}(P_{\\mathrm{tot}}(R_{50}))$\"\n",
    "#     },\n",
    "#     \"log_halo_mass\": {\n",
    "#         \"symbol\": r\"$\\log_{10}(M_{\\mathrm{halo}})$\"\n",
    "#     },\n",
    "#     \"log_h2_weighted_temperature_mass_average_half_light_visible_z500pc\":{\n",
    "#         \"symbol\": \"Th2\"\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# # List of relevant columns for analysis\n",
    "# x_columns = list(x_vars.keys())\n",
    "\n",
    "# target_column = \"log_L_co_10\"\n",
    "\n",
    "# X = data_df[x_columns].values\n",
    "# y = data_df[target_column].values\n",
    "\n",
    "\n",
    "# # Define the symbolic regressor\n",
    "# model = PySRRegressor(\n",
    "#     niterations=40,               # Number of evolutionary iterations\n",
    "#     binary_operators=[\"+\", \"-\", \"*\", \"/\"],\n",
    "#     unary_operators=[\"exp\", \"log\"],\n",
    "#     model_selection=\"best\",      # Choose the best model by loss\n",
    "#     elementwise_loss=\"loss(prediction, target) = (prediction - target)^2\",  # Mean squared error\n",
    "#     verbosity=1,\n",
    "# )\n",
    "\n",
    "# # Fit the model\n",
    "# model.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd78b42-1bb3-4e92-a1dd-920dda4e77cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping feature column names to their LaTeX-formatted symbols\n",
    "x_vars = {\n",
    "    \"log_metallicity_gas_half_light_visible_z500pc\": {\n",
    "        \"symbol\": r\"$\\log_{10}(Z_{\\mathrm{gas}}(R_{50}))$\"\n",
    "    },\n",
    "    \"log_metalicity_star_half_light_visible_z500pc\": {\n",
    "        \"symbol\": r\"$\\log_{10}(Z_{\\star}(R_{50}))$\"\n",
    "    },\n",
    "    \"log_sfr_10Myr\": {\n",
    "        \"symbol\": r\"$\\log_{10}(\\mathrm{SFR}_{10\\,\\mathrm{Myr}})$\"\n",
    "    },\n",
    "    \"log_star_mass\": {\n",
    "        \"symbol\": r\"$\\log_{10}(M_\\star)$\"\n",
    "    },\n",
    "    \"log_gas_mass\": {\n",
    "        \"symbol\": r\"$\\log_{10}(M_{\\mathrm{gas}})$\"\n",
    "    }, \n",
    "    \"log_Pgas_half_light_visible_z500pc\": {\n",
    "        \"symbol\": r\"$\\log_{10}(P_{\\mathrm{gas}}(R_{50}))$\"\n",
    "    },\n",
    "    \"log_Pstar_half_light_visible_z500pc\": {\n",
    "        \"symbol\": r\"$\\log_{10}(P_{\\mathrm{star}}(R_{50}))$\"\n",
    "    },\n",
    "    \"log_Ptotal_half_light_visible_z500pc\": {\n",
    "        \"symbol\": r\"$\\log_{10}(P_{\\mathrm{tot}}(R_{50}))$\"\n",
    "    },\n",
    "    \"log_halo_mass\": {\n",
    "        \"symbol\": r\"$\\log_{10}(M_{\\mathrm{halo}})$\"\n",
    "    },\n",
    "    \"log_h2_weighted_temperature_mass_average_half_light_visible_z500pc\":{\n",
    "        \"symbol\": \"Th2\"\n",
    "    },\n",
    "}\n",
    "\n",
    "# List of relevant columns for analysis\n",
    "x_columns = list(x_vars.keys())\n",
    "\n",
    "target_column = \"log_L_co_10\"\n",
    "\n",
    "X = data_df[x_columns].values\n",
    "y = data_df[target_column].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d656fee-b35e-44ea-9c27-1ff81a7deb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to save the file \n",
    "save_base_fdir = \"/scratch/m/murray/dtolgay/post_processing_fire_outputs/skirt/python_files/analyze_hden_metallicity_turbulence_isrf_radius/notebooks/symbollic_regression/outputs\"\n",
    "save_fname = \"model1\"\n",
    "save_fdir = f\"{save_base_fdir}/{save_fname}\"\n",
    "\n",
    "# Define the settings for PySRRegressor\n",
    "settings_for_pysrRegressor= {\n",
    "    \"n_iterations\": 40,\n",
    "    \"binary_operators\": [\"+\", \"-\", \"*\", \"/\"],\n",
    "    \"unary_operators\": [\"pow_10(x) = 10^x\"],  # Julia definition\n",
    "    \"extra_sympy_mappings\": {\n",
    "        \"pow_10\": lambda x: 10**x  # Python syntax\n",
    "    },\n",
    "    \"model_selection\": \"best\",      # Choose the best model by loss\n",
    "    \"elementwise_loss\": \"loss(prediction, target) = (prediction - target)^2\",  # Mean squared error\n",
    "    \"verbosity\": 0,\n",
    "    \"warm_start\": True,\n",
    "    \"output_directory\": save_fdir\n",
    "}\n",
    "\n",
    "\n",
    "# Define the symbolic regressor\n",
    "model = PySRRegressor(\n",
    "    niterations=40,               # Number of evolutionary iterations\n",
    "    binary_operators=[\"+\", \"-\"],\n",
    "    unary_operators=[\n",
    "        \"pow_10(x) = 10^x\",  \n",
    "    ], # These should be Julia definition\n",
    "    extra_sympy_mappings={\n",
    "        \"pow_10\": lambda x: 10**x\n",
    "    }, # This should be in python syntax\n",
    "    model_selection=\"best\",      # Choose the best model by loss\n",
    "    elementwise_loss=\"loss(prediction, target) = (prediction - target)^2\",  # Mean squared error\n",
    "    verbosity=0,\n",
    "    warm_start=True,\n",
    "    output_directory=\"model\"\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X,y)\n",
    "\n",
    "# Write the options to a txt file. \n",
    "with open(f\"{save_fdir}/options.txt\", \"w\") as f:\n",
    "    for key, value in settings_for_pysrRegressor.items():\n",
    "        f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "# Write the used x and y columns to a txt file\n",
    "with open(f\"{save_fdir}/used_columns.txt\", \"w\") as f:\n",
    "    f.write(\"Used x columns:\\n\")\n",
    "    for col in x_columns:\n",
    "        f.write(f\"{col}\\n\")\n",
    "    \n",
    "    f.write(\"\\nUsed y column:\\n\")\n",
    "    f.write(f\"{target_column}\\n\")\n",
    "\n",
    "\n",
    "print(f\"Files are saved to {save_fdir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4333871-7fef-449b-84ab-50530e5d72ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show best equation\n",
    "print(model)\n",
    "\n",
    "# Predict using symbolic model\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d565340-7a68-4d8c-a732-73b06a273901",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.equations_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2950328-3951-498d-b3da-a68b2f8ec50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_psyr_results(model, model_number, actual_y, X, ax_main, ax_resid, x_columns, x_vars):\n",
    "    y_pred = model.predict(X, model_number)\n",
    "    equation_raw = str(model.equations_.iloc[model_number]['sympy_format'])\n",
    "    residuals = actual_y - y_pred\n",
    "\n",
    "    # Find the std of the residuals \n",
    "    std = np.std(residuals)\n",
    "    \n",
    "    # x = y \n",
    "    x_dummy = np.linspace(min(actual_y), max(actual_y), num=100)\n",
    "    y_dummy = x_dummy\n",
    "    \n",
    "    # Replace x0, x1, ... with LaTeX labels\n",
    "    for i, col in enumerate(x_columns):\n",
    "        label = x_vars[col][\"symbol\"]\n",
    "        equation_raw = equation_raw.replace(f'x{i}', label)\n",
    "\n",
    "    # Plot actual vs predicted\n",
    "    ax_main.scatter(actual_y, y_pred, label=equation_raw, s=10)\n",
    "    ax_main.plot(x_dummy, y_dummy, label=\"x=y\", color = \"red\")\n",
    "    ax_main.set_ylabel(\"Prediction\")\n",
    "    ax_main.set_title(f\"Model {model_number} σ = {std:.2f}\")\n",
    "    ax_main.legend(fontsize='x-small', loc='upper left')\n",
    "    ax_main.tick_params(labelbottom=False)\n",
    "    # Plot residuals\n",
    "    ax_resid.scatter(actual_y, residuals, color='gray', s=10)\n",
    "    ax_resid.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "    ax_resid.set_xlabel(\"FIRE Calculation\")\n",
    "    ax_resid.set_ylabel(\"Residuals\")\n",
    "    ax_resid.set_ylim([-2, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacd039a-59b5-4dcf-ad56-204ceaa3eb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_models = len(model.equations_)\n",
    "ncols = 3\n",
    "nrows = int(np.ceil(n_models / ncols))\n",
    "\n",
    "fig = plt.figure(figsize=(5 * ncols, 4 * nrows), dpi=100)\n",
    "\n",
    "outer = gridspec.GridSpec(nrows, ncols, wspace=0.3, hspace=0.4)\n",
    "\n",
    "for i, model_number in enumerate(model.equations_.index):\n",
    "    row, col = divmod(i, ncols)\n",
    "    inner = gridspec.GridSpecFromSubplotSpec(\n",
    "        2, 1, subplot_spec=outer[row, col], height_ratios=[3, 1], hspace=0.05\n",
    "    )\n",
    "\n",
    "    ax_main = plt.Subplot(fig, inner[0])\n",
    "    ax_resid = plt.Subplot(fig, inner[1], sharex=ax_main)\n",
    "\n",
    "    fig.add_subplot(ax_main)\n",
    "    fig.add_subplot(ax_resid)\n",
    "\n",
    "    plot_psyr_results(\n",
    "        model=model,\n",
    "        model_number=model_number,\n",
    "        actual_y=y,\n",
    "        X=X,\n",
    "        ax_main=ax_main,\n",
    "        ax_resid=ax_resid,\n",
    "        x_columns=x_columns,\n",
    "        x_vars=x_vars\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3892433-7e06-4872-9147-559d4340912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.equations_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616ee24a-04bb-42c6-af5b-cac6aeba7e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the std for every prediction \n",
    "importlib.reload(func_log_reg)\n",
    "\n",
    "model = func_log_reg.calculate_std_for_every_model(model = model, X = X, y_expected = y)\n",
    "\n",
    "x_names = [f\"{i}\" for i in range(len(model.equations_))] \n",
    "std_array = model.equations_['std'].values\n",
    "\n",
    "# Plot the scatter reduction plot \n",
    "plt.figure(figsize=(12,6), dpi=300, facecolor=\"white\")\n",
    "# Add gray background for alternating regions\n",
    "for i in range(len(x_names)):\n",
    "    if i % 2 == 1:  # Add gray background to every other x tick region\n",
    "        plt.axvspan(i - 0.5, i + 0.5, color='lightgray', alpha=0.5)\n",
    "\n",
    "# Scatter plot\n",
    "plt.scatter(\n",
    "    range(len(x_names)),  # Adjust x values to match tick positions\n",
    "    std_array,\n",
    "    color='maroon',\n",
    "    marker='s',\n",
    ")\n",
    "\n",
    "\n",
    "# Customize x-axis\n",
    "plt.xticks(range(len(x_names)), x_names, rotation=0)  # Set tick positions and labels\n",
    "plt.xlabel(\"Model #\")\n",
    "plt.ylabel(r\"σ\")\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "plt.grid(True, axis=\"y\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f96f2c-9761-4d85-b689-b30a829f0800",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64640abd-db7f-4143-b67b-86b921c520f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.equations_.loc[5, 'sympy_format']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba7f97b-052f-4cae-a56c-5e27d5fd9c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.equations_.loc[6, 'sympy_format']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
