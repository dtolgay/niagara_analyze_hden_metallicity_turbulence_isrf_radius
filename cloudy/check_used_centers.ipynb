{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"/scratch/m/murray/dtolgay\")\n",
    "from tools import constants\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_training_data(base_file_dir, main_directory, file_name, base_line_names):\n",
    "\n",
    "    #################################################\n",
    "    # Get the trained data\n",
    "\n",
    "    print(\"Training data is started to be read.\")\n",
    "\n",
    "    line_names = []\n",
    "    for line_name in base_line_names:\n",
    "        line_names.append(f\"I_{line_name}\")\n",
    "\n",
    "    column_names = [\n",
    "        \"log_metallicity\",\n",
    "        \"log_hden\",\n",
    "        \"log_turbulence\",\n",
    "        \"log_isrf\",\n",
    "        \"log_radius\",\n",
    "    ]  + line_names\n",
    "\n",
    "    # Read file\n",
    "    path2TrainingData = f\"{base_file_dir}/{main_directory}/{file_name}\"\n",
    "    unprocessed_train_data = pd.DataFrame(\n",
    "        np.loadtxt(fname=path2TrainingData),\n",
    "        columns=column_names,\n",
    "    )\n",
    "\n",
    "    ############## Process the cloudy data \n",
    "    # Discard all nan values \n",
    "    print(\"Dropping NaN containing lines\")\n",
    "    unprocessed_train_data = unprocessed_train_data.dropna()\n",
    "\n",
    "    # Check if all intensities are positive and set 0 values to epsilon\n",
    "    print(f\"Check if all intensities are positive. Then set 0 values to {epsilon}\")\n",
    "    all_positive_columns = (unprocessed_train_data[line_names] >= 0).all().all()\n",
    "    if all_positive_columns:\n",
    "        print(f\"All of the intensity values are non-negative. Continuing...\")\n",
    "    else:\n",
    "        # Set values smaller or equal to zero to epsilon in specified columns\n",
    "        for col in line_names:\n",
    "            unprocessed_train_data[col] = unprocessed_train_data[col].map(lambda x: epsilon if x <= 0 else x)\n",
    "        print(f\"Not all intensities are are non-negative. Setting them to epsilon\")\n",
    "\n",
    "\n",
    "    line_names_with_log = []\n",
    "    for column in line_names:\n",
    "        unprocessed_train_data[f\"log_{column}\"] = np.log10(unprocessed_train_data[column])\n",
    "        line_names_with_log.append(f\"log_{column}\") # Store the new line names\n",
    "\n",
    "\n",
    "    train_data_df = unprocessed_train_data[[\n",
    "        \"log_metallicity\",\n",
    "        \"log_hden\",\n",
    "        \"log_turbulence\",\n",
    "        \"log_isrf\",\n",
    "        \"log_radius\",\n",
    "        ] + line_names_with_log]  # Only use the log of the line luminosities    \n",
    "\n",
    "    # # Double check if there is any NaN\n",
    "    # if (np.isnan(train_data_df.values).any()):\n",
    "    #     print(\"Still there are NaN values. Exiting with code 1...\")\n",
    "    #     exit(1)\n",
    "    # elif (np.isinf(train_data_df.values).any()):\n",
    "    #     print(\"Still there are inf values. Exiting with code 2...\")\n",
    "    #     exit(2)\n",
    "\n",
    "    ######\n",
    "    # Add the column density data to interpolate that too \n",
    "    train_data_df['log_column_density'] = np.log10(\n",
    "        (10**train_data_df['log_hden'] / constants.cm2pc**3) * (10**train_data_df['log_radius']) * (mu * constants.proton_mass * constants.kg2Msolar)\n",
    "    ) # Msolar / pc^2\n",
    "\n",
    "    print(f\"{path2TrainingData} is read.\")\n",
    "\n",
    "\n",
    "    return train_data_df, line_names_with_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data is started to be read.\n",
      "Dropping NaN containing lines\n",
      "Check if all intensities are positive. Then set 0 values to 1e-30\n",
      "Not all intensities are are non-negative. Setting them to epsilon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5ca081fd1869>:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_df['log_column_density'] = np.log10(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/m/murray/dtolgay/cloudy_runs/z_0/cr_1_CO87_CII_H_O3/cr_1_CO87_CII_H_O3_metallicity_above_minus_2/I_line_values_without_reversing.txt is read.\n",
      "Training data is started to be read.\n",
      "Dropping NaN containing lines\n",
      "Check if all intensities are positive. Then set 0 values to 1e-30\n",
      "Not all intensities are are non-negative. Setting them to epsilon\n",
      "/scratch/m/murray/dtolgay/cloudy_runs/z_0/cr_1_CO87_CII_H_O3/cr_1_CO87_CII_H_O3_metallicity_minus2_minus3point5/I_line_values_without_reversing.txt is read.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5ca081fd1869>:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_df['log_column_density'] = np.log10(\n"
     ]
    }
   ],
   "source": [
    "epsilon = 1e-30\n",
    "mu = 1.38 # Krumholz and Gnedin \n",
    "\n",
    "base_line_names = [\n",
    "    \"ly_alpha\",\n",
    "    \"h_alpha\",\n",
    "    \"h_beta\",\n",
    "    \"co_10\",\n",
    "    \"co_21\",\n",
    "    \"co_32\",\n",
    "    \"co_43\",\n",
    "    \"co_54\",\n",
    "    \"co_65\",\n",
    "    \"co_76\",\n",
    "    \"co_87\",\n",
    "    \"13co\",\n",
    "    \"c2\",\n",
    "    \"o3_88\",\n",
    "    \"o3_5006\",\n",
    "    \"o3_4958\",        \n",
    "]\n",
    "\n",
    "# 1st set of run\n",
    "train_data_base_file_dir_1 = \"/scratch/m/murray/dtolgay/cloudy_runs/z_0\"\n",
    "train_data_main_directory_1 = \"cr_1_CO87_CII_H_O3/cr_1_CO87_CII_H_O3_metallicity_above_minus_2\" \n",
    "\n",
    "train_data_df_1, line_names_with_log = read_training_data(\n",
    "    base_file_dir = train_data_base_file_dir_1, \n",
    "    main_directory = train_data_main_directory_1, \n",
    "    file_name = \"I_line_values_without_reversing.txt\", \n",
    "    base_line_names = base_line_names\n",
    ")    \n",
    "\n",
    "# 2nd set of run\n",
    "train_data_base_file_dir_2 = \"/scratch/m/murray/dtolgay/cloudy_runs/z_0\"\n",
    "train_data_main_directory_2 = \"cr_1_CO87_CII_H_O3/cr_1_CO87_CII_H_O3_metallicity_minus2_minus3point5\" \n",
    "\n",
    "train_data_df_2, line_names_with_log = read_training_data(\n",
    "    base_file_dir = train_data_base_file_dir_2, \n",
    "    main_directory = train_data_main_directory_2, \n",
    "    file_name = \"I_line_values_without_reversing.txt\", \n",
    "    base_line_names = base_line_names\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['log_metallicity', 'log_hden', 'log_turbulence', 'log_isrf',\n",
       "       'log_radius', 'log_I_ly_alpha', 'log_I_h_alpha', 'log_I_h_beta',\n",
       "       'log_I_co_10', 'log_I_co_21', 'log_I_co_32', 'log_I_co_43',\n",
       "       'log_I_co_54', 'log_I_co_65', 'log_I_co_76', 'log_I_co_87',\n",
       "       'log_I_13co', 'log_I_c2', 'log_I_o3_88', 'log_I_o3_5006',\n",
       "       'log_I_o3_4958', 'log_column_density'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df_2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_metallicity: [-2.  -1.5 -1.  -0.5  0.   0.5  1. ]\n",
      "log_hden: [-5. -4. -3. -2. -1.  0.  1.  2.  3.  4.  5.]\n",
      "log_turbulence: [-3. -2. -1.  0.  1.  2.  3.]\n",
      "log_isrf: [-5.  -4.5 -4.  -3.5 -3.  -2.5 -2.  -1.5 -1.  -0.5  0.   0.5  1.   1.5\n",
      "  2.   2.5  3.   3.5  4.   4.5  5. ]\n",
      "log_radius: [0.  0.5 1.  1.5 2.  2.5 3.  3.5 4.  4.5 5. ]\n",
      "\n",
      "\n",
      "\n",
      "log_metallicity: [-3.5 -3.  -2.5]\n",
      "log_hden: [-5. -4. -3. -2. -1.  0.  1.  2.  3.  4.  5.]\n",
      "log_turbulence: [-3. -2. -1.  0.  1.  2.  3.]\n",
      "log_isrf: [-5.  -4.5 -4.  -3.5 -3.  -2.5 -2.  -1.5 -1.  -0.5  0.   0.5  1.   1.5\n",
      "  2.   2.5  3.   3.5  4.   4.5  5. ]\n",
      "log_radius: [0.  0.5 1.  1.5 2.  2.5 3.  3.5 4.  4.5 5. ]\n"
     ]
    }
   ],
   "source": [
    "columns = [\n",
    "    \"log_metallicity\",\n",
    "    \"log_hden\",\n",
    "    \"log_turbulence\",\n",
    "    \"log_isrf\",\n",
    "    \"log_radius\"\n",
    "]\n",
    "\n",
    "for column in columns: \n",
    "    print(f\"{column}: {np.unique(train_data_df_1[column])}\")\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "\n",
    "for column in columns: \n",
    "    print(f\"{column}: {np.unique(train_data_df_2[column])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
