{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94893c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import sys\n",
    "sys.path.append(\"/home/m/murray/dtolgay/scratch\")\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from scipy.spatial import KDTree\n",
    "from time import time \n",
    "from scipy.interpolate import LinearNDInterpolator, NearestNDInterpolator\n",
    "\n",
    "from tools import constants\n",
    "\n",
    "# Global variables\n",
    "epsilon = 1e-30\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68dac2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_name, galaxy_type, redshift, max_workers = \"m12i_res7100_md\", \"zoom_in\", \"0.0\", 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c56e8225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cloudy_gas_particles(cloudy_gas_particles_file_directory):\n",
    "    # Define the column names based on your description\n",
    "    gas_column_names = [\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        \"z\",\n",
    "        \"smoothing_length\",\n",
    "        \"mass\",\n",
    "        \"metallicity\",\n",
    "        \"temperature\",\n",
    "        \"vx\",\n",
    "        \"vy\",\n",
    "        \"vz\",\n",
    "        \"hden\",\n",
    "        \"radius\",\n",
    "        \"sfr\",\n",
    "        \"turbulence\",\n",
    "        \"density\",\n",
    "        \"mu_theoretical\",\n",
    "        \"average_sobolev_smoothingLength\",\n",
    "        \"index\",\n",
    "        \"isrf\",\n",
    "    ]\n",
    "\n",
    "    gas_particles_df = pd.read_csv(\n",
    "        f\"{cloudy_gas_particles_file_directory}/cloudy_gas_particles.txt\",\n",
    "        delim_whitespace=True,\n",
    "        comment=\"#\",\n",
    "        names=gas_column_names,\n",
    "    )\n",
    "\n",
    "    gas_particles_df['dummy_radius'] = gas_particles_df['smoothing_length'] / 2 # TODO: Delete \n",
    "\n",
    "    # isrf of the gas particles can be zero, therefore set them equal to a very small number\n",
    "    gas_particles_df.loc[gas_particles_df[\"isrf\"] == 0, \"isrf\"] = 1e-30\n",
    "\n",
    "    # Extend the dataframe by adding the log of the parameters\n",
    "    gas_particles_df[\n",
    "        [\n",
    "            \"log_metallicity\",\n",
    "            \"log_density\",\n",
    "            \"log_turbulence\",\n",
    "            \"log_isrf\",\n",
    "            \"log_hden\",\n",
    "            \"log_radius\",\n",
    "            \"log_smoothing_length\",\n",
    "            \"log_average_sobolev_smoothingLength\",\n",
    "            \"log_dummy_radius\", # TODO: Delete\n",
    "        ]\n",
    "    ] = np.log10(\n",
    "        gas_particles_df[\n",
    "            [\n",
    "                \"metallicity\",\n",
    "                \"density\",\n",
    "                \"turbulence\",\n",
    "                \"isrf\",\n",
    "                \"hden\",\n",
    "                \"radius\",\n",
    "                \"smoothing_length\",\n",
    "                \"average_sobolev_smoothingLength\",\n",
    "                \"dummy_radius\", # TODO: Delete\n",
    "            ]\n",
    "        ]\n",
    "    )  # Take the log of the gas properties and interpolate using these logarithmic values.  \n",
    "\n",
    "    print(f\"{cloudy_gas_particles_file_directory}/cloudy_gas_particles.txt read and dataframe is created!\")      \n",
    "    \n",
    "    return gas_particles_df, gas_column_names \n",
    "\n",
    "def read_training_data(base_file_dir, main_directory, file_name, properties_column_names):\n",
    "\n",
    "    #################################################\n",
    "    # Get the trained data\n",
    "    print(\"Training data is started to be read.\")\n",
    "\n",
    "    # Read file\n",
    "    path2TrainingData = f\"{base_file_dir}/{main_directory}/{file_name}\"\n",
    "    unprocessed_train_data = pd.read_csv(path2TrainingData) \n",
    "\n",
    "    ############## Process the cloudy data \n",
    "    # Take the log of the properties \n",
    "    properties_column_names_with_log = []\n",
    "    for property in properties_column_names:\n",
    "        unprocessed_train_data[property] += epsilon # Add a very small number \n",
    "        unprocessed_train_data[f\"log_{property}\"] = np.log10(unprocessed_train_data[property])\n",
    "        properties_column_names_with_log.append(f\"log_{property}\")\n",
    "\n",
    "    # Discard all nan values \n",
    "    print(\"Dropping NaN containing lines\")\n",
    "    processed_train_data = unprocessed_train_data.dropna()        \n",
    "    train_data_df = processed_train_data.drop(properties_column_names, axis=1) # Drop the columns which log is not taken.\n",
    "\n",
    "    # # Double check if there is any NaN\n",
    "    # if (np.isnan(train_data_df.values).any()):\n",
    "    #     print(\"Still there are NaN values. Exiting with code 1...\")\n",
    "    #     exit(1)\n",
    "    # elif (np.isinf(train_data_df.values).any()):\n",
    "    #     print(\"Still there are inf values. Exiting with code 2...\")\n",
    "    #     exit(2)\n",
    "\n",
    "    ######\n",
    "    # Add the column density data to interpolate that too \n",
    "    train_data_df['log_column_density'] = np.log10(\n",
    "        (10**train_data_df['log_hden'] / constants.cm2pc**3) * (10**train_data_df['log_radius']) * (constants.mu_h * constants.proton_mass * constants.kg2Msolar)\n",
    "    ) # Msolar / pc^2\n",
    "\n",
    "    print(f\"{path2TrainingData} is read.\")\n",
    "\n",
    "\n",
    "    return train_data_df, properties_column_names_with_log\n",
    "\n",
    "def split_dataframe(df, max_workers):\n",
    "    # Create different chunks of of dataframe to run them parallely\n",
    "    n = len(df)\n",
    "    chunk_size = -(\n",
    "        -n // max_workers\n",
    "    )  # Ceiling division to ensure all rows are included\n",
    "\n",
    "    # Split the dataframe into chunks and store in an array\n",
    "    return [df[i : i + chunk_size] for i in range(0, n, chunk_size)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5960f16b",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81ac459f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------ m12i_res7100_md ------------------------------------------\n",
      "/home/m/murray/dtolgay/scratch/post_processing_fire_outputs/skirt/runs_hden_radius/zoom_in/z0.0/m12i_res7100_md/voronoi_1e6/cloudy_gas_particles.txt read and dataframe is created!\n",
      "Training data is started to be read.\n",
      "Dropping NaN containing lines\n",
      "/scratch/m/murray/dtolgay/cloudy_runs/z_0/cr_1_CO87_CII_H_O3/cr_1_CO87_CII_H_O3_metallicity_above_minus_2/other_properties.csv is read.\n",
      "Training data is started to be read.\n",
      "Dropping NaN containing lines\n",
      "/scratch/m/murray/dtolgay/cloudy_runs/z_0/cr_1_CO87_CII_H_O3/cr_1_CO87_CII_H_O3_metallicity_minus2_minus3point5/other_properties.csv is read.\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "# directory_name = \"lichen_voronoi_1e6\"\n",
    "directory_name = \"voronoi_1e6\"\n",
    "# directory_name = \"voronoi_1e6_improved_wavelength_bin\"\n",
    "# directory_name = \"trial1\"\n",
    "\n",
    "print(\n",
    "    f\"------------------------------------------ {galaxy_name} ------------------------------------------\"\n",
    ")\n",
    "\n",
    "## Check if file exits. If it exists do not continue running the code, if not run the code.\n",
    "cloudy_gas_particles_file_directory = f\"/home/m/murray/dtolgay/scratch/post_processing_fire_outputs/skirt/runs_hden_radius/{galaxy_type}/z{redshift}/{galaxy_name}/{directory_name}\"\n",
    "# cloudy_gas_particles_file_directory = f\"/home/m/murray/dtolgay/scratch/cloudy_runs/z_3/m12f_res7100_md_test\"\n",
    "\n",
    "\n",
    "# Read gas particles \n",
    "gas_particles_df, gas_column_names = read_cloudy_gas_particles(cloudy_gas_particles_file_directory)\n",
    "\n",
    "gas_particles_df = gas_particles_df.iloc[0:10].copy()\n",
    "\n",
    "# Split dataframe into several dataframes to run the parallely. \n",
    "gas_particles_df_chunks = split_dataframe(\n",
    "        df=gas_particles_df,\n",
    "        max_workers=max_workers, \n",
    "    )\n",
    "\n",
    "################ Read training data particles \n",
    "properties_column_names = [\n",
    "    \"fh2\",\n",
    "    \"fCO\",\n",
    "]\n",
    "\n",
    "# 1st set of run\n",
    "train_data_base_file_dir_1 = \"/scratch/m/murray/dtolgay/cloudy_runs/z_0\"\n",
    "train_data_main_directory_1 = \"cr_1_CO87_CII_H_O3/cr_1_CO87_CII_H_O3_metallicity_above_minus_2\" \n",
    "\n",
    "train_data_df_1, properties_column_names_with_log = read_training_data(\n",
    "    base_file_dir = train_data_base_file_dir_1, \n",
    "    main_directory = train_data_main_directory_1, \n",
    "    file_name = \"other_properties.csv\", \n",
    "    properties_column_names = properties_column_names,\n",
    ")    \n",
    "\n",
    "# 2nd set of run\n",
    "train_data_base_file_dir_2 = \"/scratch/m/murray/dtolgay/cloudy_runs/z_0\"\n",
    "train_data_main_directory_2 = \"cr_1_CO87_CII_H_O3/cr_1_CO87_CII_H_O3_metallicity_minus2_minus3point5\" \n",
    "\n",
    "train_data_df_2, properties_column_names_with_log = read_training_data(\n",
    "    base_file_dir = train_data_base_file_dir_2, \n",
    "    main_directory = train_data_main_directory_2, \n",
    "    file_name = \"other_properties.csv\", \n",
    "    properties_column_names = properties_column_names,\n",
    ")    \n",
    "\n",
    "\n",
    "# Concattanete two dataframes \n",
    "train_data_df = pd.concat([train_data_df_2, train_data_df_1])\n",
    "train_data_file_paths = [f\"{train_data_base_file_dir_1}/{train_data_main_directory_1}\", f\"{train_data_base_file_dir_2}/{train_data_main_directory_2}\"]\n",
    "\n",
    "# train_data_file_paths = [f\"{train_data_base_file_dir_1}/{train_data_main_directory_1}\"]\n",
    "# train_data_df = train_data_df_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fc79b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>smoothing_length</th>\n",
       "      <th>mass</th>\n",
       "      <th>metallicity</th>\n",
       "      <th>temperature</th>\n",
       "      <th>vx</th>\n",
       "      <th>vy</th>\n",
       "      <th>vz</th>\n",
       "      <th>...</th>\n",
       "      <th>dummy_radius</th>\n",
       "      <th>log_metallicity</th>\n",
       "      <th>log_density</th>\n",
       "      <th>log_turbulence</th>\n",
       "      <th>log_isrf</th>\n",
       "      <th>log_hden</th>\n",
       "      <th>log_radius</th>\n",
       "      <th>log_smoothing_length</th>\n",
       "      <th>log_average_sobolev_smoothingLength</th>\n",
       "      <th>log_dummy_radius</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8155.11156</td>\n",
       "      <td>2523.78963</td>\n",
       "      <td>295.767503</td>\n",
       "      <td>494.771024</td>\n",
       "      <td>9633.96595</td>\n",
       "      <td>1.543016</td>\n",
       "      <td>1.329689e+06</td>\n",
       "      <td>-440.727295</td>\n",
       "      <td>103.712943</td>\n",
       "      <td>181.075122</td>\n",
       "      <td>...</td>\n",
       "      <td>247.385512</td>\n",
       "      <td>0.188371</td>\n",
       "      <td>-25.383051</td>\n",
       "      <td>2.441073</td>\n",
       "      <td>0.635261</td>\n",
       "      <td>-1.390178</td>\n",
       "      <td>2.192656</td>\n",
       "      <td>2.694404</td>\n",
       "      <td>2.404975</td>\n",
       "      <td>2.393374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8009.17409</td>\n",
       "      <td>2389.75543</td>\n",
       "      <td>246.704012</td>\n",
       "      <td>586.104359</td>\n",
       "      <td>8752.24193</td>\n",
       "      <td>1.722534</td>\n",
       "      <td>2.101607e+06</td>\n",
       "      <td>-448.361308</td>\n",
       "      <td>143.592455</td>\n",
       "      <td>56.359671</td>\n",
       "      <td>...</td>\n",
       "      <td>293.052179</td>\n",
       "      <td>0.236168</td>\n",
       "      <td>-25.644843</td>\n",
       "      <td>2.319640</td>\n",
       "      <td>0.663333</td>\n",
       "      <td>-1.653066</td>\n",
       "      <td>2.266025</td>\n",
       "      <td>2.767975</td>\n",
       "      <td>2.479325</td>\n",
       "      <td>2.466945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7988.03240</td>\n",
       "      <td>2330.81139</td>\n",
       "      <td>410.916168</td>\n",
       "      <td>328.450397</td>\n",
       "      <td>8200.12148</td>\n",
       "      <td>0.994449</td>\n",
       "      <td>4.059210e+04</td>\n",
       "      <td>-109.426567</td>\n",
       "      <td>187.687041</td>\n",
       "      <td>-165.466676</td>\n",
       "      <td>...</td>\n",
       "      <td>164.225199</td>\n",
       "      <td>-0.002417</td>\n",
       "      <td>-24.919246</td>\n",
       "      <td>2.047164</td>\n",
       "      <td>0.663333</td>\n",
       "      <td>-0.941648</td>\n",
       "      <td>2.014726</td>\n",
       "      <td>2.516470</td>\n",
       "      <td>2.247593</td>\n",
       "      <td>2.215440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7902.90863</td>\n",
       "      <td>2389.85935</td>\n",
       "      <td>460.785347</td>\n",
       "      <td>276.410299</td>\n",
       "      <td>14864.19290</td>\n",
       "      <td>1.922749</td>\n",
       "      <td>1.015830e+04</td>\n",
       "      <td>-101.605009</td>\n",
       "      <td>281.626390</td>\n",
       "      <td>44.834390</td>\n",
       "      <td>...</td>\n",
       "      <td>138.205150</td>\n",
       "      <td>0.283923</td>\n",
       "      <td>-24.439030</td>\n",
       "      <td>1.822882</td>\n",
       "      <td>0.580017</td>\n",
       "      <td>-0.755093</td>\n",
       "      <td>1.940761</td>\n",
       "      <td>2.441554</td>\n",
       "      <td>2.236150</td>\n",
       "      <td>2.140524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7973.95872</td>\n",
       "      <td>2427.62253</td>\n",
       "      <td>399.528474</td>\n",
       "      <td>331.981654</td>\n",
       "      <td>10381.17430</td>\n",
       "      <td>1.691503</td>\n",
       "      <td>4.792360e+04</td>\n",
       "      <td>-124.733355</td>\n",
       "      <td>214.637333</td>\n",
       "      <td>-111.297868</td>\n",
       "      <td>...</td>\n",
       "      <td>165.990827</td>\n",
       "      <td>0.228273</td>\n",
       "      <td>-24.830582</td>\n",
       "      <td>1.745932</td>\n",
       "      <td>0.663333</td>\n",
       "      <td>-0.858713</td>\n",
       "      <td>2.019314</td>\n",
       "      <td>2.521114</td>\n",
       "      <td>2.279911</td>\n",
       "      <td>2.220084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7890.54377</td>\n",
       "      <td>2470.06370</td>\n",
       "      <td>602.389166</td>\n",
       "      <td>159.979949</td>\n",
       "      <td>9352.69791</td>\n",
       "      <td>1.740791</td>\n",
       "      <td>9.014615e+03</td>\n",
       "      <td>-110.398699</td>\n",
       "      <td>250.745290</td>\n",
       "      <td>-0.053703</td>\n",
       "      <td>...</td>\n",
       "      <td>79.989975</td>\n",
       "      <td>0.240747</td>\n",
       "      <td>-23.924958</td>\n",
       "      <td>1.295796</td>\n",
       "      <td>0.633560</td>\n",
       "      <td>-0.253746</td>\n",
       "      <td>1.702336</td>\n",
       "      <td>2.204066</td>\n",
       "      <td>2.283109</td>\n",
       "      <td>1.903036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7828.08767</td>\n",
       "      <td>2503.68247</td>\n",
       "      <td>570.979823</td>\n",
       "      <td>160.544134</td>\n",
       "      <td>8857.03221</td>\n",
       "      <td>1.449421</td>\n",
       "      <td>1.092657e+04</td>\n",
       "      <td>-111.958055</td>\n",
       "      <td>310.089589</td>\n",
       "      <td>27.370154</td>\n",
       "      <td>...</td>\n",
       "      <td>80.272067</td>\n",
       "      <td>0.161194</td>\n",
       "      <td>-23.953826</td>\n",
       "      <td>1.408569</td>\n",
       "      <td>0.633560</td>\n",
       "      <td>-0.275519</td>\n",
       "      <td>1.704076</td>\n",
       "      <td>2.205594</td>\n",
       "      <td>2.364501</td>\n",
       "      <td>1.904564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7754.92834</td>\n",
       "      <td>2410.81187</td>\n",
       "      <td>557.783877</td>\n",
       "      <td>236.760581</td>\n",
       "      <td>11355.52720</td>\n",
       "      <td>2.158300</td>\n",
       "      <td>1.167867e+04</td>\n",
       "      <td>-93.482017</td>\n",
       "      <td>338.936176</td>\n",
       "      <td>60.106515</td>\n",
       "      <td>...</td>\n",
       "      <td>118.380291</td>\n",
       "      <td>0.334112</td>\n",
       "      <td>-24.347536</td>\n",
       "      <td>1.821547</td>\n",
       "      <td>0.580017</td>\n",
       "      <td>-0.662765</td>\n",
       "      <td>1.871285</td>\n",
       "      <td>2.374309</td>\n",
       "      <td>2.145097</td>\n",
       "      <td>2.073279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7821.29993</td>\n",
       "      <td>2433.04870</td>\n",
       "      <td>645.132350</td>\n",
       "      <td>135.969381</td>\n",
       "      <td>7259.10054</td>\n",
       "      <td>0.422022</td>\n",
       "      <td>3.048350e+03</td>\n",
       "      <td>-131.429354</td>\n",
       "      <td>230.359092</td>\n",
       "      <td>-4.555720</td>\n",
       "      <td>...</td>\n",
       "      <td>67.984690</td>\n",
       "      <td>-0.374665</td>\n",
       "      <td>-23.824196</td>\n",
       "      <td>1.129041</td>\n",
       "      <td>0.372245</td>\n",
       "      <td>-0.141852</td>\n",
       "      <td>1.632064</td>\n",
       "      <td>2.133441</td>\n",
       "      <td>2.209432</td>\n",
       "      <td>1.832411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7789.05919</td>\n",
       "      <td>2432.59306</td>\n",
       "      <td>657.669738</td>\n",
       "      <td>130.570215</td>\n",
       "      <td>9402.21890</td>\n",
       "      <td>1.829502</td>\n",
       "      <td>6.354094e+01</td>\n",
       "      <td>-136.728369</td>\n",
       "      <td>245.432536</td>\n",
       "      <td>5.195918</td>\n",
       "      <td>...</td>\n",
       "      <td>65.285107</td>\n",
       "      <td>0.262333</td>\n",
       "      <td>-23.658503</td>\n",
       "      <td>1.052487</td>\n",
       "      <td>0.372245</td>\n",
       "      <td>0.011751</td>\n",
       "      <td>1.614282</td>\n",
       "      <td>2.115844</td>\n",
       "      <td>2.095744</td>\n",
       "      <td>1.814814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x           y           z  smoothing_length         mass  \\\n",
       "0  8155.11156  2523.78963  295.767503        494.771024   9633.96595   \n",
       "1  8009.17409  2389.75543  246.704012        586.104359   8752.24193   \n",
       "2  7988.03240  2330.81139  410.916168        328.450397   8200.12148   \n",
       "3  7902.90863  2389.85935  460.785347        276.410299  14864.19290   \n",
       "4  7973.95872  2427.62253  399.528474        331.981654  10381.17430   \n",
       "5  7890.54377  2470.06370  602.389166        159.979949   9352.69791   \n",
       "6  7828.08767  2503.68247  570.979823        160.544134   8857.03221   \n",
       "7  7754.92834  2410.81187  557.783877        236.760581  11355.52720   \n",
       "8  7821.29993  2433.04870  645.132350        135.969381   7259.10054   \n",
       "9  7789.05919  2432.59306  657.669738        130.570215   9402.21890   \n",
       "\n",
       "   metallicity   temperature          vx          vy          vz  ...  \\\n",
       "0     1.543016  1.329689e+06 -440.727295  103.712943  181.075122  ...   \n",
       "1     1.722534  2.101607e+06 -448.361308  143.592455   56.359671  ...   \n",
       "2     0.994449  4.059210e+04 -109.426567  187.687041 -165.466676  ...   \n",
       "3     1.922749  1.015830e+04 -101.605009  281.626390   44.834390  ...   \n",
       "4     1.691503  4.792360e+04 -124.733355  214.637333 -111.297868  ...   \n",
       "5     1.740791  9.014615e+03 -110.398699  250.745290   -0.053703  ...   \n",
       "6     1.449421  1.092657e+04 -111.958055  310.089589   27.370154  ...   \n",
       "7     2.158300  1.167867e+04  -93.482017  338.936176   60.106515  ...   \n",
       "8     0.422022  3.048350e+03 -131.429354  230.359092   -4.555720  ...   \n",
       "9     1.829502  6.354094e+01 -136.728369  245.432536    5.195918  ...   \n",
       "\n",
       "   dummy_radius  log_metallicity  log_density  log_turbulence  log_isrf  \\\n",
       "0    247.385512         0.188371   -25.383051        2.441073  0.635261   \n",
       "1    293.052179         0.236168   -25.644843        2.319640  0.663333   \n",
       "2    164.225199        -0.002417   -24.919246        2.047164  0.663333   \n",
       "3    138.205150         0.283923   -24.439030        1.822882  0.580017   \n",
       "4    165.990827         0.228273   -24.830582        1.745932  0.663333   \n",
       "5     79.989975         0.240747   -23.924958        1.295796  0.633560   \n",
       "6     80.272067         0.161194   -23.953826        1.408569  0.633560   \n",
       "7    118.380291         0.334112   -24.347536        1.821547  0.580017   \n",
       "8     67.984690        -0.374665   -23.824196        1.129041  0.372245   \n",
       "9     65.285107         0.262333   -23.658503        1.052487  0.372245   \n",
       "\n",
       "   log_hden  log_radius  log_smoothing_length  \\\n",
       "0 -1.390178    2.192656              2.694404   \n",
       "1 -1.653066    2.266025              2.767975   \n",
       "2 -0.941648    2.014726              2.516470   \n",
       "3 -0.755093    1.940761              2.441554   \n",
       "4 -0.858713    2.019314              2.521114   \n",
       "5 -0.253746    1.702336              2.204066   \n",
       "6 -0.275519    1.704076              2.205594   \n",
       "7 -0.662765    1.871285              2.374309   \n",
       "8 -0.141852    1.632064              2.133441   \n",
       "9  0.011751    1.614282              2.115844   \n",
       "\n",
       "   log_average_sobolev_smoothingLength  log_dummy_radius  \n",
       "0                             2.404975          2.393374  \n",
       "1                             2.479325          2.466945  \n",
       "2                             2.247593          2.215440  \n",
       "3                             2.236150          2.140524  \n",
       "4                             2.279911          2.220084  \n",
       "5                             2.283109          1.903036  \n",
       "6                             2.364501          1.904564  \n",
       "7                             2.145097          2.073279  \n",
       "8                             2.209432          1.832411  \n",
       "9                             2.095744          1.814814  \n",
       "\n",
       "[10 rows x 29 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gas_particles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f039664",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_interpolator(k, gas, gas_data_column_names, tree, train_data_df, train_data_column_names, target_column_names, interpolator=\"LinearNDInterpolator\"):\n",
    "    # Query the tree for neighbors\n",
    "    distances, indices = tree.query(gas[gas_data_column_names].to_numpy(), k=k)\n",
    "    \n",
    "    # Set up linearNDInterpolator\n",
    "    if interpolator == \"LinearNDInterpolator\":  \n",
    "        interpolator = LinearNDInterpolator(\n",
    "            points=train_data_df.iloc[indices][train_data_column_names].to_numpy(),\n",
    "            values=train_data_df.iloc[indices][target_column_names].to_numpy()\n",
    "        )\n",
    "    elif interpolator == \"NearestNDInterpolator\":\n",
    "        interpolator = NearestNDInterpolator(\n",
    "            train_data_df.iloc[indices][train_data_column_names].to_numpy(),\n",
    "            train_data_df.iloc[indices][target_column_names].to_numpy()\n",
    "        )\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    return interpolator\n",
    "\n",
    "def interpolate_otherProperties(gas_particles_df, train_data_df, properties_column_names_with_log):\n",
    "\n",
    "    print(\"I am in the interpolate_otherProperties\")\n",
    "\n",
    "    train_data_column_names = [\n",
    "        \"log_metallicity\",\n",
    "        \"log_hden\",\n",
    "        \"log_turbulence\",\n",
    "        \"log_isrf\",\n",
    "        \"log_radius\",    \n",
    "    ]    \n",
    "\n",
    "    tree = KDTree(\n",
    "        train_data_df[train_data_column_names].to_numpy(),\n",
    "    ) # Create a tree for the training data\n",
    "\n",
    "    scale_length = [\n",
    "        \"log_average_sobolev_smoothingLength\"\n",
    "    ]\n",
    "\n",
    "    gas_data_column_names = [\n",
    "        \"log_metallicity\",\n",
    "        \"log_hden\",\n",
    "        \"log_turbulence\",\n",
    "        \"log_isrf\",      \n",
    "    ] + scale_length\n",
    "\n",
    "    gas_indices_luminosities = []\n",
    "    \n",
    "    intial_index = gas_particles_df.iloc[0]['index']\n",
    "    for index, gas in gas_particles_df.iterrows():\n",
    "        if intial_index == 0:\n",
    "            if (gas['index'] % int(1e5) == 1):\n",
    "                print(f\"{gas['index']} finished. Left {len(gas_particles_df) - gas['index']}\")\n",
    "\n",
    "        # List of k values to try in order\n",
    "        k_values = [50, 100, 500, 1000, 2000, 3000, 5000, int(1e4)]        \n",
    "\n",
    "        for k in k_values: \n",
    "            try:\n",
    "                # Get the interpolator \n",
    "                interpolator = prepare_interpolator(\n",
    "                        k = k, \n",
    "                        gas = gas, \n",
    "                        gas_data_column_names = gas_data_column_names, \n",
    "                        tree = tree, \n",
    "                        train_data_df = train_data_df, \n",
    "                        train_data_column_names = train_data_column_names, \n",
    "                        target_column_names = properties_column_names_with_log, \n",
    "                        interpolator=\"LinearNDInterpolator\"\n",
    "                    )\n",
    "                \n",
    "                # Check if there are NaN values \n",
    "                interpolated_Y_values = 10**interpolator(gas[gas_data_column_names])[0] # It returns an array of arrays. That's why [0] is done.\n",
    "\n",
    "                # If there exist any NaN change iterate to the next k value:\n",
    "                if np.isnan(interpolated_Y_values).any(): \n",
    "                    if k < 300:\n",
    "                        continue\n",
    "                    else:\n",
    "                        # use nearestNDInterpolator\n",
    "                        interpolator = prepare_interpolator(\n",
    "                                k = k, \n",
    "                                gas = gas, \n",
    "                                gas_data_column_names = gas_data_column_names, \n",
    "                                tree = tree, \n",
    "                                train_data_df = train_data_df, \n",
    "                                train_data_column_names = train_data_column_names, \n",
    "                                target_column_names = properties_column_names_with_log, \n",
    "                                interpolator=\"NearestNDInterpolator\"\n",
    "                            )\n",
    "                        interpolated_Y_values = 10**interpolator(gas[gas_data_column_names])[0] # It returns an array of arrays. That's why [0] is done.\n",
    "                        print(\"NearestNDInterpolator used\") # TODO: Delete\n",
    "                        break\n",
    "                else: \n",
    "                    print(\"LinearNDInterpolator used\") # TODO: Delete\n",
    "                    break  # Break out of the loop if and there exist no NaN values \n",
    "\n",
    "            except Exception as e:\n",
    "                # If it fails with the current k, continue to the next one\n",
    "                continue\n",
    "        \n",
    "        # If interpolator is not able to be constructed, exit with an error code.\n",
    "        if interpolator == None:\n",
    "            print(f\"Error: interpolator is None for index: {gas['index']}\")\n",
    "            exit(99)\n",
    "\n",
    "        # Append the gas indices and properties each other. \n",
    "        gas_indices_luminosities.append(\n",
    "            np.concatenate(([gas['index']], interpolated_Y_values))\n",
    "        )\n",
    "\n",
    "    return gas_indices_luminosities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d65fc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in the interpolate_otherProperties\n",
      "LinearNDInterpolator used\n",
      "1.0 finished. Left 9.0\n",
      "LinearNDInterpolator used\n",
      "LinearNDInterpolator used\n",
      "LinearNDInterpolator used\n",
      "LinearNDInterpolator used\n",
      "LinearNDInterpolator used\n",
      "LinearNDInterpolator used\n",
      "LinearNDInterpolator used\n",
      "LinearNDInterpolator used\n",
      "LinearNDInterpolator used\n",
      "Flattening the array\n",
      "Lengths of luminosities and gas particles are the same. Merging can be done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "########\n",
    "# Interpolate\n",
    "with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = [\n",
    "        executor.submit(interpolate_otherProperties, gas_particles_df_chunk, train_data_df, properties_column_names_with_log)\n",
    "        for gas_particles_df_chunk in gas_particles_df_chunks\n",
    "    ]\n",
    "    gas_indices_interpolatedValues_chunks = [future.result() for future in futures]       \n",
    "\n",
    "# Flatten the array\n",
    "print(\"Flattening the array\")\n",
    "gas_indices_interpolatedValues = [] \n",
    "for interpolated_value_for_gas_particles_in_the_chunk in gas_indices_interpolatedValues_chunks:\n",
    "    for interpolated_value_for_gas_particle in interpolated_value_for_gas_particles_in_the_chunk:\n",
    "        gas_indices_interpolatedValues.append(interpolated_value_for_gas_particle)\n",
    "\n",
    "\n",
    "\n",
    "# gas_indices_interpolatedValues = interpolate_otherProperties(\n",
    "#     gas_particles_df=gas_particles_df, \n",
    "#     train_data_df=train_data_df, \n",
    "#     properties_column_names_with_log=properties_column_names_with_log\n",
    "#     )\n",
    "\n",
    "column_names = ['index'] + properties_column_names # Now this is not log because I took the exponential when I am interpolating \n",
    "gas_indices_Yinterpolated = pd.DataFrame(gas_indices_interpolatedValues, columns=column_names)\n",
    "\n",
    "### \n",
    "# Merge two dataframes\n",
    "if len(gas_indices_Yinterpolated) == len(gas_particles_df):\n",
    "    print(\"Lengths of luminosities and gas particles are the same. Merging can be done.\")\n",
    "    merged_df = gas_particles_df.merge(gas_indices_Yinterpolated, how='left', on='index', validate='one_to_one') # Check if it is one to one \n",
    "else:\n",
    "    print(\"Lengths of luminosities and gas particles are NOT same. Exiting with code 3...\")\n",
    "    exit(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "107efd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fh2</th>\n",
       "      <th>fCO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.190741e-12</td>\n",
       "      <td>8.765854e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.836694e-15</td>\n",
       "      <td>1.219259e-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.349086e-13</td>\n",
       "      <td>3.956539e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.492946e-11</td>\n",
       "      <td>1.255279e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.190741e-12</td>\n",
       "      <td>8.765854e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.473104e-06</td>\n",
       "      <td>1.263396e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.473104e-06</td>\n",
       "      <td>1.263396e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.492946e-11</td>\n",
       "      <td>1.255279e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.115192e-08</td>\n",
       "      <td>1.792349e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.164997e-06</td>\n",
       "      <td>1.468022e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fh2           fCO\n",
       "0  1.190741e-12  8.765854e-25\n",
       "1  1.836694e-15  1.219259e-30\n",
       "2  8.349086e-13  3.956539e-25\n",
       "3  4.492946e-11  1.255279e-22\n",
       "4  1.190741e-12  8.765854e-25\n",
       "5  1.473104e-06  1.263396e-13\n",
       "6  1.473104e-06  1.263396e-13\n",
       "7  4.492946e-11  1.255279e-22\n",
       "8  1.115192e-08  1.792349e-15\n",
       "9  5.164997e-06  1.468022e-12"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[properties_column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5daa7d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fh2</th>\n",
       "      <th>fCO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.765810e-13</td>\n",
       "      <td>6.586721e-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.724033e-14</td>\n",
       "      <td>2.399328e-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.997853e-13</td>\n",
       "      <td>3.606018e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.918439e-10</td>\n",
       "      <td>4.270764e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.260302e-11</td>\n",
       "      <td>6.991438e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.594181e-06</td>\n",
       "      <td>1.017638e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.543294e-08</td>\n",
       "      <td>4.962646e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.587235e-10</td>\n",
       "      <td>2.906478e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.136497e-08</td>\n",
       "      <td>4.995571e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.554083e-05</td>\n",
       "      <td>3.056528e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fh2           fCO\n",
       "0  1.765810e-13  6.586721e-27\n",
       "1  4.724033e-14  2.399328e-27\n",
       "2  8.997853e-13  3.606018e-25\n",
       "3  1.918439e-10  4.270764e-21\n",
       "4  2.260302e-11  6.991438e-23\n",
       "5  1.594181e-06  1.017638e-14\n",
       "6  8.543294e-08  4.962646e-16\n",
       "7  4.587235e-10  2.906478e-20\n",
       "8  1.136497e-08  4.995571e-16\n",
       "9  1.554083e-05  3.056528e-12"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[properties_column_names]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
